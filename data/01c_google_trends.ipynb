{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "involved-century",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/using-google-trends-at-scale-1c8b902b6bfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CONDA_DEFAULT_ENV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jens/miniconda3/envs/ml4t\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CONDA_PREFIX\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "above-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import monthrange\n",
    "from datetime import timedelta, datetime, date\n",
    "from functools import partial\n",
    "from random import randrange, randint\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from pytrends.exceptions import ResponseError\n",
    "from pytrends.request import TrendReq\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_timeframe_daily_resolution(start: date, stop: date) -> str:\n",
    "    \"\"\"Given two dates, returns a string representing the interval between the\n",
    "    dates. This is string is used to retrieve data for a specific time frame\n",
    "    from Google Trends.\n",
    "    \"\"\"\n",
    "    return f\"{start.strftime('%Y-%m-%d')} {stop.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "def get_timeframe_hourly_resolution(start: datetime, stop: datetime) -> str:\n",
    "    \"\"\"Given two datetimes, returns a string representing the interval between the\n",
    "    dates. This is string is used to retrieve data for a specific time frame\n",
    "    from Google Trends.\n",
    "    \"\"\"\n",
    "    return f\"{start.strftime('%Y-%m-%dT%H')} {stop.strftime('%Y-%m-%dT%H')}\"\n",
    "\n",
    "\n",
    "\n",
    "def _fetch_data(pytrends, build_payload, timeframe: str) -> pd.DataFrame:\n",
    "    \"\"\"Attempts to fecth data and retries in case of a ResponseError.\"\"\"\n",
    "    attempts, fetched = 0, False\n",
    "    if randint(0, 10) == 0:\n",
    "        print(\"sleep 60 s\")\n",
    "        sleep(60)\n",
    "\n",
    "    while not fetched:\n",
    "        try:\n",
    "            build_payload(timeframe=timeframe)\n",
    "        except Exception:\n",
    "            wait_time = 300 * attempts  # Start with 0 due to timeouts\n",
    "            print(f'Trying again in {wait_time / 60:.0f} minutes.')\n",
    "            sleep(wait_time)\n",
    "            attempts += 1\n",
    "        else:\n",
    "            result = pytrends.interest_over_time()\n",
    "            if result.empty:\n",
    "                print(\"dataframe empty, sleep 5 min\")\n",
    "                attempts += 1\n",
    "            else:\n",
    "                fetched = True\n",
    "    return pytrends.interest_over_time()\n",
    "\n",
    "\n",
    "def get_hourly_data(search_term: str,\n",
    "                    start_year: int = 2020,\n",
    "                    start_month: int = 1,\n",
    "                    start_day: int = 1,\n",
    "                    stop_year: int = 2021,\n",
    "                    stop_month: int = 12,\n",
    "                    stop_day: int = 31,\n",
    "                    geo: str = '',  # for worldwide aggregation\n",
    "                    tz: int = 0,  # for utc!\n",
    "                    cat: int = 0,\n",
    "                    verbose: bool = True,\n",
    "                    clean: bool = True,\n",
    "                    wait_time: float = 5.0,\n",
    "                    shift_hourly: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Given a search term, fetches daily search volume data from Google Trends and\n",
    "    returns results in a pandas DataFrame.\n",
    "    Details: Due to the way Google Trends scales and returns data, special\n",
    "    care needs to be taken to make the daily data comparable over different\n",
    "    months. To do that, we download daily data on a month by month basis,\n",
    "    and also monthly data. The monthly data is downloaded in one go, so that\n",
    "    the monthly values are comparable amongst themselves and can be used to\n",
    "    scale the daily data. In a given month, the daily data is scaled so that\n",
    "    the month by month average of daily values is equal to the values at the\n",
    "    monthly frequency. That is, the daily data is scaled by multiplying the\n",
    "    daily values by the ratio of the monthly series value to the monthly\n",
    "    average of the daily data.\n",
    "\n",
    "    Args:\n",
    "        search_term (str): search_term to fetch daily data for.\n",
    "        start_year (int): First year to fetch data for. Starts at the beginning\n",
    "            of this year (1st of January).\n",
    "        start_month (int): First month of the first year\n",
    "        start_day (int): First day of the first year\n",
    "        stop_year (int): Last year to fetch data for (inclusive).\n",
    "        stop_month (int): Last month of the last year\n",
    "        stop_day (int): Last day\n",
    "        geo (str): Geographical area code. Default at 'US'.\n",
    "        tz (int): Time zone, minutes offset off GMT (240 for US EST).\n",
    "        cat (int): Category, default 0 for no category. Use trends.google.com and\n",
    "        check the header for more information.\n",
    "        verbose (bool): If True, then prints the word and current time frame\n",
    "            we are fecthing the data for.\n",
    "        clean (bool): If True, clean up the dataframe, else leave information for\n",
    "            diagnostics\n",
    "        wait_time (float): Scaling factor for how much to wait between data\n",
    "            requests. If 0, then a new request is sent at about every 0.5\n",
    "            second. The default of 5 seconds implies in a new request being\n",
    "            sent at about every 3 seconds (random).\n",
    "        shift_hourly (bool): shifts for 3 days which is useful for validation (see tests)\n",
    "    Returns:\n",
    "        complete (pd.DataFrame): Contains 4 columns.\n",
    "            The column named after the word argument contains the daily search\n",
    "            volume already scaled and comparable through time.\n",
    "            The column f'{word}_{geo}_unscaled' is the original daily data\n",
    "            fetched month by month, and it is not comparable across different\n",
    "            months (but is comparable within a month).\n",
    "            The column f'{word}_{geo}_monthly' contains the original monthly\n",
    "            data fetched at once. The values in this column have been\n",
    "            backfilled so that there are no NaN present.\n",
    "            The column 'scale' contains the scale used to obtain the scaled\n",
    "            daily data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up start and stop dates\n",
    "    start_date = datetime(start_year, start_month, start_day)\n",
    "    # stop_date cannot be later than today's date\n",
    "    stop_date = min([datetime(stop_year, stop_month, stop_day), datetime.today()])\n",
    "\n",
    "    # Start pytrends for US region\n",
    "    pytrends = TrendReq(tz=tz)\n",
    "    # Initialize build_payload with the search_term we need data for\n",
    "    build_payload = partial(pytrends.build_payload, kw_list=[search_term], cat=cat, geo=geo, gprop='')\n",
    "\n",
    "\n",
    "    daily = get_daily_gtrends(build_payload, geo, pytrends, search_term, start_date, stop_date, verbose, wait_time)\n",
    "    monthly = get_monthly_gtrends(build_payload, pytrends, search_term, start_date, stop_date, verbose)\n",
    "\n",
    "    daily['interest_daily_monthly_mean'] = daily['interest_daily_raw'].resample('M').mean()\n",
    "    daily['interest_daily_monthly_mean'].bfill(inplace=True)  # Fill in backward because 'monthly' resampling is the\n",
    "    # other way round\n",
    "    monthly_daily_interest = daily.join(monthly)\n",
    "\n",
    "\n",
    "    # fill NaN values\n",
    "    monthly_daily_interest['interest_monthly'].ffill(inplace=True)\n",
    "    # compute month_by_day_scale\n",
    "    monthly_daily_interest['month_day_scale'] = monthly_daily_interest['interest_monthly'] / monthly_daily_interest['interest_daily_monthly_mean']\n",
    "    monthly_daily_interest['interest_daily'] = monthly_daily_interest['interest_daily_raw'] * monthly_daily_interest.month_day_scale\n",
    "\n",
    "    # hourly = get_hourly_gtrends(geo, pytrends, search_term, start_date, stop_date, verbose, wait_time)\n",
    "    # Compute month by month averages of daily data\n",
    "    \"\"\"\n",
    "    if shift_hourly:\n",
    "        hourly = get_hourly_gtrends(build_payload, geo, pytrends, search_term, start_date-timedelta(days=3), stop_date, verbose, wait_time)\n",
    "    else:\n",
    "        hourly = get_hourly_gtrends(build_payload, geo, pytrends, search_term, start_date, stop_date, verbose, wait_time)\n",
    "\n",
    "    hourly['interest_hourly_7D_mean'] = hourly['interest_hourly_raw'].resample('7D').mean()\n",
    "    hourly['interest_hourly_7D_mean'].ffill(inplace=True)  # Fill in forward\n",
    "    interest = hourly.join(monthly_daily_interest)\n",
    "\n",
    "    # Compute 7D mean for hourly usage\n",
    "    interest['interest_daily_7D_mean'] = interest['interest_daily'].resample('7D').mean()\n",
    "    interest['interest_daily_7D_mean'].ffill(inplace=True)  # fill NaN values\n",
    "    # Scale hourly data by 7-day weights so the data is comparable\n",
    "\n",
    "    interest['daily_hourly_scaling'] = interest['interest_daily_7D_mean'] / interest['interest_hourly_7D_mean']\n",
    "    interest['interest_hourly'] = interest['interest_hourly_raw'] * interest.daily_hourly_scaling\n",
    "\n",
    "    interest['interest_monthly'].ffill(inplace=True)\n",
    "    interest['interest_daily'].ffill(inplace=True)\n",
    "    print('hourly mean {}'.format(interest['interest_hourly'].mean()))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if clean:\n",
    "        cols_to_keep = ['interest_monthly',\n",
    "                        'interest_daily',\n",
    "                        #'interest_hourly'\n",
    "                        ]\n",
    "        interest = monthly_daily_interest.loc[:, cols_to_keep]\n",
    "\n",
    "    print('monthly mean {}'.format(interest['interest_monthly'].mean()))\n",
    "    print('daily mean {}'.format(interest['interest_daily'].mean()))\n",
    "\n",
    "    interest['search_term'] = search_term\n",
    "    interest['google_category'] = cat\n",
    "    interest.set_index(['search_term', 'google_category'], inplace=True, append=True)\n",
    "    # interest.stack(['search_term', 'google_category'])\n",
    "    return interest\n",
    "\n",
    "\n",
    "def get_hourly_gtrends(build_payload, geo, pytrends, search_term, start_date, stop_date, verbose, wait_time):\n",
    "    # Get daily data, month by month\n",
    "    results = []\n",
    "    attempts = 0\n",
    "    # If a timeout or too many requests error occur we need to adjust wait time\n",
    "    current = start_date\n",
    "    while current < stop_date:\n",
    "        end_date = current + timedelta(days=7)\n",
    "\n",
    "        timeframe = get_timeframe_hourly_resolution(current, end_date)\n",
    "        if verbose:\n",
    "            print(f'{search_term}/{geo}:{timeframe}')\n",
    "        result = _fetch_data(pytrends, build_payload, timeframe)\n",
    "\n",
    "        result.rename(columns={search_term: 'interest_hourly_raw',\n",
    "                               'isPartial': 'hourly_isPartial'}, inplace=True)\n",
    "        result = result['interest_hourly_raw'].apply(lambda x: max(x, 0.1))\n",
    "\n",
    "        if verbose:\n",
    "            print(result)\n",
    "        results.append(result)\n",
    "        current = end_date + timedelta(hours=1)\n",
    "\n",
    "        # Don't go too fast or Google will send 429s\n",
    "        sleep(randrange(10, round(10 * wait_time)) / 10)\n",
    "\n",
    "    # Concatenate daily data into a single dataframe\n",
    "    daily = pd.concat(results)\n",
    "    return daily\n",
    "\n",
    "\"\"\"\n",
    "def get_hourly_gtrends_old(geo, pytrends, search_term, start_date, stop_date, verbose, wait_time):\n",
    "    # Get hourly data, week by week\n",
    "    results = []\n",
    "    # If a timeout or too many requests error occur we need to adjust wait time\n",
    "    current = start_date\n",
    "    while current < stop_date:\n",
    "        end_date = current + timedelta(days=7) - timedelta(hours=1)\n",
    "        print(f'{search_term} {geo} : {current} to {end_date}')\n",
    "        result = pytrends.get_historical_interest([search_term], year_start=current.year,\n",
    "                                                  month_start=current.month,\n",
    "                                                  day_start=current.day,\n",
    "                                                  hour_start=current.hour,\n",
    "                                                  year_end=end_date.year,\n",
    "                                                  month_end=end_date.month,\n",
    "                                                  day_end=end_date.day,\n",
    "                                                  hour_end=end_date.hour,\n",
    "                                                  cat=0, geo='', gprop='', sleep=0)\n",
    "        result.rename(columns={search_term: 'interest_hourly_raw',\n",
    "                               'isPartial': 'hourly_isPartial'}, inplace=True)\n",
    "\n",
    "        results.append(result)\n",
    "        if verbose:\n",
    "            print(result)\n",
    "        current = current + timedelta(days=7)\n",
    "        # Don't go too fast or Google will send 429s\n",
    "        sleep(randrange(10, round(10 * wait_time)) / 10)\n",
    "    # Concatenate daily data into a single dataframe\n",
    "    hourly = pd.concat(results)\n",
    "    return hourly\n",
    "\"\"\"\n",
    "\n",
    "def get_daily_gtrends(build_payload, geo, pytrends, search_term, start_date, stop_date, verbose, wait_time):\n",
    "    # Get daily data, month by month\n",
    "    results = []\n",
    "    # If a timeout or too many requests error occur we need to adjust wait time\n",
    "    current = start_date\n",
    "    while current < stop_date:\n",
    "        lastDateOfMonth = datetime(current.year, current.month,\n",
    "                                   monthrange(current.year, current.month)[1])\n",
    "        timeframe = get_timeframe_daily_resolution(current, lastDateOfMonth)\n",
    "        print(f'{search_term}/{geo}:{timeframe}')\n",
    "        result = _fetch_data(pytrends, build_payload, timeframe)\n",
    "\n",
    "        result.rename(columns={search_term: 'interest_daily_raw',\n",
    "                               'isPartial': 'daily_isPartial'}, inplace=True)\n",
    "        # result = result['interest_daily_raw'].apply(lambda x: max(x, 0.1))\n",
    "\n",
    "        if verbose:\n",
    "            print(result)\n",
    "        if not result.empty:\n",
    "            results.append(result)\n",
    "            current = lastDateOfMonth + timedelta(days=1)\n",
    "\n",
    "        # Don't go too fast or Google will send 429s\n",
    "        sleep(randrange(10, round(10 * wait_time)) / 10)\n",
    "    # Concatenate daily data into a single dataframe\n",
    "    daily = pd.concat(results)\n",
    "    return daily\n",
    "\n",
    "\n",
    "def get_monthly_gtrends(build_payload, pytrends, search_term, start_date, stop_date, verbose):\n",
    "    # Obtain monthly data for all months in years [2004, stop_year]\n",
    "    monthly = _fetch_data(pytrends, build_payload,\n",
    "                          get_timeframe_daily_resolution(datetime(2004, 1, 1), stop_date))[start_date:stop_date]\n",
    "    monthly.rename(columns={search_term: 'interest_monthly',\n",
    "                            'isPartial': 'monthly_isPartial'}, inplace=True)\n",
    "    monthly = monthly['interest_monthly'].apply(lambda x: max(x, 0.1))\n",
    "    if verbose:\n",
    "        print(monthly)\n",
    "    return monthly"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Get the coins and coin names and save google trend data for the words and categories "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md \n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "charitable-beverage",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_STORE = '../data/crypto.h5'\n",
    "\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    # todo insert market\n",
    "    market = store['coingecko/top100/market']\n",
    "    # cats = store['coingecko/top100/cats']\n",
    "    # col_list = ['name', 'id']\n",
    "    # market_cut = market.loc[:, col_list]\n",
    "    prices = store['crypto/caggle/prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(Index(['btc', 'ltc', 'eth', 'etc', 'xmr', 'xrp', 'miota', 'eos', 'neo', 'trx',\n        'dai', 'mtn', 'xlm', 'mkr', 'man', 'vet', 'xtz', 'bsv', 'usdt', 'usdc',\n        'btt', 'atom', 'wbtc', 'okb', 'algo', 'ftt', 'doge', 'ada', 'dot',\n        'ksm', 'uni', 'fil', 'sol', 'aave', 'avax', 'link', 'luna', 'bch'],\n       dtype='object', name='symbol'),\n 38)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the list of symbols from prices data\n",
    "prices_symbols = prices.index.get_level_values('symbol').unique()\n",
    "prices_symbols, len(prices_symbols)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crypto/gtrends/btc_gtrend\n"
     ]
    }
   ],
   "source": [
    "def symbol_to_store_path(symbol):\n",
    "    return 'crypto/gtrends/' + symbol + '_gtrend'\n",
    "\n",
    "print(symbol_to_store_path('btc'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                         id    market_cap               name genesis_date  \\\nsymbol base                                                                 \nbtc    usd          bitcoin  850591196779            Bitcoin   2009-01-03   \neth    usd         ethereum  406828020424           Ethereum   2015-07-30   \nbnb    usd      binancecoin   81364766850       Binance Coin   2017-07-08   \nxrp    usd           ripple   76304936290                XRP          NaT   \nada    usd          cardano   68023186087            Cardano          NaT   \n...                     ...           ...                ...          ...   \nicx    usd             icon    1261199302               ICON   2017-09-19   \npax    usd   paxos-standard    1232255212     Paxos Standard          NaT   \narrr   usd     pirate-chain    1230249576       Pirate Chain   2018-08-29   \nsteth  usd     staked-ether    1215795625  Lido Staked Ether          NaT   \ntusd   usd         true-usd    1193335811            TrueUSD   2018-03-05   \n\n             market_cap_rank hashing_algorithm  coingecko_rank  \\\nsymbol base                                                      \nbtc    usd                 1           SHA-256               2   \neth    usd                 2            Ethash               3   \nbnb    usd                 3              None               5   \nxrp    usd                 4              None               9   \nada    usd                 5              None               6   \n...                      ...               ...             ...   \nicx    usd                96              None              66   \npax    usd                97              None             168   \narrr   usd                97          Equihash             133   \nsteth  usd                99              None             573   \ntusd   usd               100              None             110   \n\n             coingecko_score  developer_score  community_score  \\\nsymbol base                                                      \nbtc    usd            81.149           98.874           74.606   \neth    usd            78.085           97.194           65.231   \nbnb    usd            67.430           73.243           66.596   \nxrp    usd            65.219           71.122           54.329   \nada    usd            66.641           70.441           61.873   \n...                      ...              ...              ...   \nicx    usd            50.558           57.689           43.226   \npax    usd            40.076           47.966            8.260   \narrr   usd            43.566           55.799           36.531   \nsteth  usd            26.947            0.000           26.400   \ntusd   usd            45.559           65.722            8.667   \n\n             liquidity_score  public_interest_score  \nsymbol base                                          \nbtc    usd           100.084                    0.0  \neth    usd            99.843                    0.0  \nbnb    usd            80.872                    0.0  \nxrp    usd            86.490                    0.0  \nada    usd            86.307                    0.0  \n...                      ...                    ...  \nicx    usd            56.885                    0.0  \npax    usd            55.094                    0.0  \narrr   usd            31.661                    0.0  \nsteth  usd            29.507                    0.0  \ntusd   usd            60.013                    0.0  \n\n[100 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>id</th>\n      <th>market_cap</th>\n      <th>name</th>\n      <th>genesis_date</th>\n      <th>market_cap_rank</th>\n      <th>hashing_algorithm</th>\n      <th>coingecko_rank</th>\n      <th>coingecko_score</th>\n      <th>developer_score</th>\n      <th>community_score</th>\n      <th>liquidity_score</th>\n      <th>public_interest_score</th>\n    </tr>\n    <tr>\n      <th>symbol</th>\n      <th>base</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>btc</th>\n      <th>usd</th>\n      <td>bitcoin</td>\n      <td>850591196779</td>\n      <td>Bitcoin</td>\n      <td>2009-01-03</td>\n      <td>1</td>\n      <td>SHA-256</td>\n      <td>2</td>\n      <td>81.149</td>\n      <td>98.874</td>\n      <td>74.606</td>\n      <td>100.084</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>eth</th>\n      <th>usd</th>\n      <td>ethereum</td>\n      <td>406828020424</td>\n      <td>Ethereum</td>\n      <td>2015-07-30</td>\n      <td>2</td>\n      <td>Ethash</td>\n      <td>3</td>\n      <td>78.085</td>\n      <td>97.194</td>\n      <td>65.231</td>\n      <td>99.843</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>bnb</th>\n      <th>usd</th>\n      <td>binancecoin</td>\n      <td>81364766850</td>\n      <td>Binance Coin</td>\n      <td>2017-07-08</td>\n      <td>3</td>\n      <td>None</td>\n      <td>5</td>\n      <td>67.430</td>\n      <td>73.243</td>\n      <td>66.596</td>\n      <td>80.872</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>xrp</th>\n      <th>usd</th>\n      <td>ripple</td>\n      <td>76304936290</td>\n      <td>XRP</td>\n      <td>NaT</td>\n      <td>4</td>\n      <td>None</td>\n      <td>9</td>\n      <td>65.219</td>\n      <td>71.122</td>\n      <td>54.329</td>\n      <td>86.490</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ada</th>\n      <th>usd</th>\n      <td>cardano</td>\n      <td>68023186087</td>\n      <td>Cardano</td>\n      <td>NaT</td>\n      <td>5</td>\n      <td>None</td>\n      <td>6</td>\n      <td>66.641</td>\n      <td>70.441</td>\n      <td>61.873</td>\n      <td>86.307</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>icx</th>\n      <th>usd</th>\n      <td>icon</td>\n      <td>1261199302</td>\n      <td>ICON</td>\n      <td>2017-09-19</td>\n      <td>96</td>\n      <td>None</td>\n      <td>66</td>\n      <td>50.558</td>\n      <td>57.689</td>\n      <td>43.226</td>\n      <td>56.885</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>pax</th>\n      <th>usd</th>\n      <td>paxos-standard</td>\n      <td>1232255212</td>\n      <td>Paxos Standard</td>\n      <td>NaT</td>\n      <td>97</td>\n      <td>None</td>\n      <td>168</td>\n      <td>40.076</td>\n      <td>47.966</td>\n      <td>8.260</td>\n      <td>55.094</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>arrr</th>\n      <th>usd</th>\n      <td>pirate-chain</td>\n      <td>1230249576</td>\n      <td>Pirate Chain</td>\n      <td>2018-08-29</td>\n      <td>97</td>\n      <td>Equihash</td>\n      <td>133</td>\n      <td>43.566</td>\n      <td>55.799</td>\n      <td>36.531</td>\n      <td>31.661</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>steth</th>\n      <th>usd</th>\n      <td>staked-ether</td>\n      <td>1215795625</td>\n      <td>Lido Staked Ether</td>\n      <td>NaT</td>\n      <td>99</td>\n      <td>None</td>\n      <td>573</td>\n      <td>26.947</td>\n      <td>0.000</td>\n      <td>26.400</td>\n      <td>29.507</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>tusd</th>\n      <th>usd</th>\n      <td>true-usd</td>\n      <td>1193335811</td>\n      <td>TrueUSD</td>\n      <td>2018-03-05</td>\n      <td>100</td>\n      <td>None</td>\n      <td>110</td>\n      <td>45.559</td>\n      <td>65.722</td>\n      <td>8.667</td>\n      <td>60.013</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crypto/gtrends/google_trends_df not found. \n",
      "symbol ('btc', 'usd')\n",
      "name Bitcoin\n",
      "symbol ('eth', 'usd')\n",
      "name Ethereum\n",
      "symbol ('bnb', 'usd')\n",
      "name Binance Coin\n",
      "symbol ('xrp', 'usd')\n",
      "name XRP\n",
      "symbol ('ada', 'usd')\n",
      "name Cardano\n",
      "symbol ('doge', 'usd')\n",
      "name Dogecoin\n",
      "symbol ('usdt', 'usd')\n",
      "name Tether\n",
      "symbol ('dot', 'usd')\n",
      "name Polkadot\n",
      "symbol ('bch', 'usd')\n",
      "name Bitcoin Cash\n",
      "symbol ('ltc', 'usd')\n",
      "name Litecoin\n",
      "symbol ('uni', 'usd')\n",
      "name Uniswap\n",
      "symbol ('link', 'usd')\n",
      "name Chainlink\n",
      "symbol ('usdc', 'usd')\n",
      "name USD Coin\n",
      "symbol ('xlm', 'usd')\n",
      "name Stellar\n",
      "symbol ('sol', 'usd')\n",
      "name Solana\n",
      "symbol ('matic', 'usd')\n",
      "name Polygon\n",
      "symbol ('etc', 'usd')\n",
      "name Ethereum Classic\n",
      "symbol ('vet', 'usd')\n",
      "name VeChain\n",
      "symbol ('theta', 'usd')\n",
      "name Theta Network\n",
      "symbol ('eos', 'usd')\n",
      "name EOS\n",
      "symbol ('trx', 'usd')\n",
      "name TRON\n",
      "symbol ('shib', 'usd')\n",
      "name Shiba Inu\n",
      "symbol ('aave', 'usd')\n",
      "name Aave\n",
      "symbol ('wbtc', 'usd')\n",
      "name Wrapped Bitcoin\n",
      "symbol ('busd', 'usd')\n",
      "name Binance USD\n",
      "symbol ('okb', 'usd')\n",
      "name OKB\n",
      "symbol ('fil', 'usd')\n",
      "name Filecoin\n",
      "symbol ('neo', 'usd')\n",
      "name NEO\n",
      "symbol ('xmr', 'usd')\n",
      "name Monero\n",
      "symbol ('luna', 'usd')\n",
      "name Terra\n",
      "symbol ('klay', 'usd')\n",
      "name Klaytn\n",
      "symbol ('ceth', 'usd')\n",
      "name cETH\n",
      "symbol ('bsv', 'usd')\n",
      "name Bitcoin SV\n",
      "symbol ('miota', 'usd')\n",
      "name IOTA\n",
      "symbol ('atom', 'usd')\n",
      "name Cosmos\n",
      "symbol ('ksm', 'usd')\n",
      "name Kusama\n",
      "symbol ('ht', 'usd')\n",
      "name Huobi Token\n",
      "symbol ('rune', 'usd')\n",
      "name THORChain\n",
      "symbol ('AVAX', 'usd')\n",
      "name Avalanche\n",
      "symbol ('xtz', 'usd')\n",
      "name Tezos\n",
      "symbol ('cake', 'usd')\n",
      "name PancakeSwap\n",
      "symbol ('dai', 'usd')\n",
      "name Dai\n",
      "symbol ('ftt', 'usd')\n",
      "name FTX Token\n",
      "symbol ('safemoon', 'usd')\n",
      "name SafeMoon\n",
      "symbol ('mkr', 'usd')\n",
      "name Maker\n",
      "symbol ('cdai', 'usd')\n",
      "name cDAI\n",
      "symbol ('algo', 'usd')\n",
      "name Algorand\n",
      "symbol ('cusdc', 'usd')\n",
      "name cUSDC\n",
      "symbol ('cro', 'usd')\n",
      "name Crypto.com Coin\n",
      "symbol ('btt', 'usd')\n",
      "name BitTorrent\n",
      "symbol ('comp', 'usd')\n",
      "name Compound\n",
      "symbol ('snx', 'usd')\n",
      "name Synthetix Network Token\n",
      "symbol ('sushi', 'usd')\n",
      "name Sushi\n",
      "symbol ('dash', 'usd')\n",
      "name Dash\n",
      "symbol ('leo', 'usd')\n",
      "name LEO Token\n",
      "symbol ('waves', 'usd')\n",
      "name Waves\n",
      "symbol ('zec', 'usd')\n",
      "name Zcash\n",
      "symbol ('cel', 'usd')\n",
      "name Celsius Network\n",
      "symbol ('yfi', 'usd')\n",
      "name yearn.finance\n",
      "symbol ('xem', 'usd')\n",
      "name NEM\n",
      "symbol ('egld', 'usd')\n",
      "name Elrond\n",
      "symbol ('tel', 'usd')\n",
      "name Telcoin\n",
      "symbol ('hbar', 'usd')\n",
      "name Hedera Hashgraph\n",
      "symbol ('dcr', 'usd')\n",
      "name Decred\n",
      "symbol ('chz', 'usd')\n",
      "name Chiliz\n",
      "symbol ('near', 'usd')\n",
      "name Near\n",
      "symbol ('zil', 'usd')\n",
      "name Zilliqa\n",
      "symbol ('amp', 'usd')\n",
      "name Amp\n",
      "symbol ('ust', 'usd')\n",
      "name TerraUSD\n",
      "symbol ('hot', 'usd')\n",
      "name Holo\n",
      "symbol ('qtum', 'usd')\n",
      "name Qtum\n",
      "symbol ('enj', 'usd')\n",
      "name Enjin Coin\n",
      "symbol ('nexo', 'usd')\n",
      "name NEXO\n",
      "symbol ('bat', 'usd')\n",
      "name Basic Attention Token\n",
      "symbol ('ftm', 'usd')\n",
      "name Fantom\n",
      "symbol ('mana', 'usd')\n",
      "name Decentraland\n",
      "symbol ('btg', 'usd')\n",
      "name Bitcoin Gold\n",
      "symbol ('ont', 'usd')\n",
      "name Ontology\n",
      "symbol ('one', 'usd')\n",
      "name Harmony\n",
      "symbol ('grt', 'usd')\n",
      "name The Graph\n",
      "symbol ('dgb', 'usd')\n",
      "name DigiByte\n",
      "symbol ('stx', 'usd')\n",
      "name Stacks\n",
      "symbol ('lusd', 'usd')\n",
      "name Liquity USD\n",
      "symbol ('hbtc', 'usd')\n",
      "name Huobi BTC\n",
      "symbol ('uma', 'usd')\n",
      "name UMA\n",
      "symbol ('nano', 'usd')\n",
      "name Nano\n",
      "symbol ('xsushi', 'usd')\n",
      "name xSUSHI\n",
      "symbol ('zrx', 'usd')\n",
      "name 0x\n",
      "symbol ('sc', 'usd')\n",
      "name Siacoin\n",
      "symbol ('zen', 'usd')\n",
      "name Horizen\n",
      "symbol ('bnt', 'usd')\n",
      "name Bancor Network Token\n",
      "symbol ('crv', 'usd')\n",
      "name Curve DAO Token\n",
      "symbol ('gt', 'usd')\n",
      "name GateToken\n",
      "symbol ('omg', 'usd')\n",
      "name OMG Network\n",
      "symbol ('hnt', 'usd')\n",
      "name Helium\n",
      "symbol ('icx', 'usd')\n",
      "name ICON\n",
      "symbol ('pax', 'usd')\n",
      "name Paxos Standard\n",
      "symbol ('arrr', 'usd')\n",
      "name Pirate Chain\n",
      "symbol ('steth', 'usd')\n",
      "name Lido Staked Ether\n",
      "symbol ('tusd', 'usd')\n",
      "name TrueUSD\n"
     ]
    }
   ],
   "source": [
    "ranked_market = market.sort_values(by='market_cap_rank')\n",
    "\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store_key = 'crypto/gtrends/google_trends_df'\n",
    "    if store_key in store:\n",
    "        google_trends_df = store[store_key]\n",
    "\n",
    "        print(f\"found {store_key}\")\n",
    "    else:\n",
    "        google_trends_df = pd.DataFrame()\n",
    "        print(f\"{store_key} not found. \")\n",
    "\n",
    "\n",
    "\n",
    "# Printing Name and AvgBill. In this case, \"x\" is a series with index of column names\n",
    "for index, contents in ranked_market.iterrows():\n",
    "    symbol = contents.name\n",
    "    symbol_name = contents['name']\n",
    "    print(\"symbol {}\\nname {}\".format(symbol, symbol_name))\n",
    "    search_terms = [contents.name, contents['name']]\n",
    "    category = 7 # finance\n",
    "    if symbol in prices_symbols:\n",
    "        for search_term in search_terms:\n",
    "            if not google_trends_df.empty:\n",
    "                print(\"google trends is not empty\")\n",
    "                if symbol in google_trends_df.index.get_level_values('symbol'):\n",
    "                    print(\"found {} in gtrends_df\".format(symbol))\n",
    "                    if search_term in google_trends_df.index.get_level_values('search_term'):\n",
    "                            print(\"found {} in gtrends_df\".format(search_term))\n",
    "                            if category in google_trends_df.index.get_level_values('google_category'):\n",
    "                                print(\"found category {} in gtrends_df\".format(category))\n",
    "                                print(\"break\")\n",
    "                                break\n",
    "            print(\"get data from google\")\n",
    "            # if not break due to already aquired data:\n",
    "            google_trend = get_hourly_data(search_term, start_year=2016, stop_year=2021,\n",
    "                                           cat=category, wait_time=10,)\n",
    "            google_trend['symbol'] = symbol\n",
    "            google_trend.set_index('symbol', inplace=True, append=True)\n",
    "\n",
    "            print(\"resulting google_trend: \\n{}\".format(google_trend))\n",
    "\n",
    "            google_trends_df = pd.concat([google_trends_df, google_trend])\n",
    "            print(\"google_trends_df: \\n{}\".format(google_trends_df))\n",
    "\n",
    "\n",
    "            with pd.HDFStore(DATA_STORE) as store:\n",
    "                store.put(store_key, google_trends_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tests for making a library"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-14-d58ba73affa6>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<ipython-input-14-d58ba73affa6>\"\u001B[0;36m, line \u001B[0;32m13\u001B[0m\n\u001B[0;31m    \u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "google_trend = get_hourly_data('AMG Mercedes', start_year=2021, stop_year=2021, stop_month=2, stop_day=28,\n",
    "                               # cat=7,\n",
    "                               clean=False)\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(24, 16))\n",
    "\n",
    "google_trend.ffill(inplace=True)\n",
    "\n",
    "google_trend.plot(ax=ax1)\n",
    "fig1.savefig('monthly_daily_interest.svg')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "google_trend_shifted = get_hourly_data('AMG Mercedes', start_year=2021, stop_year=2021, stop_month=2, stop_day=28,\n",
    "                               clean=False, shift_hourly=True)\n",
    "\n",
    "google_trend_shifted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "make sure trends are aligned by testing for the difference of a differently sampled daily period \n",
    "(already visually confirmed)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols_keep = ['interest_daily', 'interest_hourly']\n",
    "joined_gtrends = google_trend[cols_keep].join(google_trend_shifted[cols_keep]*1.01, rsuffix='_shifted')\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(32,20))\n",
    "joined_gtrends.plot(ax=ax)\n",
    "fig.savefig('shifted_validation.svg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-ceiling",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(24,16))\n",
    "\n",
    "google_trend.plot(ax=ax1)\n",
    "fig.savefig('monthly_daily_interest.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-mistress",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "google_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "google_trend_shifted.tail(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-canberra",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}